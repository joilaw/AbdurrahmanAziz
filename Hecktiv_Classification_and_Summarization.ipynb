{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAgnOa72er0T3Qm9/rj86k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joilaw/AbdurrahmanAziz/blob/master/Hecktiv_Classification_and_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09nmHQ38WYxh"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community\n",
        "!pip install replicate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API Model"
      ],
      "metadata": {
        "id": "PFYAhytDb539"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import Replicate\n",
        "import os\n",
        "from google.colab import userdata\n",
        "# Set the API token\n",
        "api_token = userdata.get('api_token')\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = api_token\n",
        "# Model setup\n",
        "model = \"ibm-granite/granite-3.3-8b-instruct\"\n",
        "output = Replicate(\n",
        "model=model,\n",
        "replicate_api_token=api_token,)"
      ],
      "metadata": {
        "id": "p_N25lBhZoRm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "ZoKkkQ5CbyWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the customer reviews\n",
        "customer_reviews = [\n",
        "\"The battery lasts all day, and the performance is\n",
        "excellent.\",\n",
        "\"The screen is too dim outdoors, but I love the colors\n",
        "indoors.\",\n",
        "\"This phone is slow and keeps crashing when I open certain\n",
        "apps.\"\n",
        "]\n",
        "# Refine the prompt to include reviews\n",
        "reviews_text = \"\\n\".join([f\"Review {i+1}: {review}\" for i, review\n",
        "in enumerate(customer_reviews)])\n",
        "prompt = f\"\"\"\n",
        "Classify these reviews as Positive, Negative, or Mixed:\n",
        "{reviews_text}\n",
        "\"\"\"\n",
        "# Invoke the model with the example prompt\n",
        "response = output.invoke(prompt)\n",
        "# Print the response\n",
        "print(\"Granite Model Response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "p6-yrkW_Z3HH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define refined prompt\n",
        "refined_prompt = f\"\"\"\n",
        "Classify these reviews as positive, negative, or mixed, and tag\n",
        "relevant categories (battery life, screen quality, or\n",
        "performance):\n",
        "{reviews_text}\n",
        "\"\"\"\n",
        "# Invoke the model with the example prompt\n",
        "response = output.invoke(refined_prompt)\n",
        "# Print the response\n",
        "print(\"Granite Model Refined Response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "LysedxHeaG7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt to complete the task in 2 steps\n",
        "multitask_prompt = f\"\"\"\n",
        "Complete the task in 2 steps.\n",
        "Step 1: Classify these reviews as positive, negative, or mixed.\n",
        "Step 2: For each review, identify relevant categories: battery\n",
        "life, screen quality, or performance.\n",
        "{reviews_text}\n",
        "\"\"\"\n",
        "response = output.invoke(multitask_prompt)\n",
        "print(\"Granite Model Response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "QaWPZF6fZ7_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the example to guide the model\n",
        "formatted_prompt = f\"\"\"\n",
        "Classify these reviews as Positive, Negative, or Mixed, and tag\n",
        "relevant categories. Use this format:\n",
        "- Sentiment: [Sentiment]\n",
        "- Categories: [Categories].\n",
        "{reviews_text}\n",
        "\"\"\"\n",
        "# Invoke the model with prompt\n",
        "response = output.invoke(formatted_prompt)\n",
        "# Print the response\n",
        "print(\"Granite Model Formatted Response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "zQ1CgVtpaBCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n"
      ],
      "metadata": {
        "id": "wo418pFIbt1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_meetings = [\n",
        "\"\"\"\n",
        "The meeting began with a discussion of the Q3 marketing budget. It\n",
        "was decided that 40% of the budget will go to digital ads, 30% to\n",
        "events, and 30% to social media campaigns. The team emphasized the\n",
        "need for influencer partnerships to increase brand visibility and\n",
        "email marketing to boost direct engagement. A pilot program to\n",
        "test new ad formats will launch next month, with the team\n",
        "reviewing results by the end of Q3.\n",
        "Later, the team discussed campaign performance metrics. ROI\n",
        "monitoring will be a top priority, and adjustments will be made\n",
        "based on performance data.\n",
        "The events team raised concerns about resource allocation for\n",
        "upcoming trade shows, and it was agreed that an additional $10,000\n",
        "would be reallocated to cover these costs.\n",
        "Lastly, the team reviewed new creative concepts for the upcoming\n",
        "campaign, deciding to proceed with Concept 8, which tested better\n",
        "among focus groups. Deadlines for campaign assets were finalized:\n",
        "all deliverables must be submitted by July 15.\n",
        "\"\"\"\n",
        "]"
      ],
      "metadata": {
        "id": "unyVNEW9bWSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Refine the prompt to include reviews\n",
        "reviews_text = \"\\n\".join([f\"Review {i+1}: {review}\" for i, review\n",
        "in enumerate(customer_meetings)])\n",
        "prompt = f\"\"\"\n",
        "Summarize this meeting:\n",
        "{reviews_text}\n",
        "\"\"\"\n",
        "# Invoke the model with example prompt\n",
        "response = output.invoke(prompt)\n",
        "# Print the response\n",
        "print(\"Granite Model Response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "sXFWzxvdbZ2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define refined prompt\n",
        "refined_prompt = f\"\"\"\n",
        "Summarize this meeting in three sentences:\n",
        "{reviews_text}\n",
        "\"\"\"\n",
        "# Invoke the model with refined prompt\n",
        "response = output.invoke(refined_prompt)\n",
        "# Print the response\n",
        "print(\"Granite Model Refined Response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "EoUzg_IEbb6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt with refined focus area prompt\n",
        "refined_focusarea_prompt = f\"\"\"\n",
        "Summarize this meeting by focusing on key points, decisions made,\n",
        "and action items:\n",
        "{reviews_text}\n",
        "\"\"\"\n",
        "response = output.invoke(refined_focusarea_prompt)\n",
        "print(\"Granite Model Response for refined focus area response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "a6YOLM2bbeO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt with refined output prompt\n",
        "refined_outputformat_prompt = f\"\"\"\n",
        "Summarize this meeting into a structured format using the following\n",
        "headings: Key Points Discussed, Decisions Made, and Action Items.\n",
        "Mention timelines.\n",
        "Include only two concise bullet points under each heading.\n",
        "{reviews_text}\n",
        "\"\"\"\n",
        "response = output.invoke(refined_outputformat_prompt)\n",
        "print(\"Granite Model Response for refined output format response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "ScstGk0Pbhr9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}